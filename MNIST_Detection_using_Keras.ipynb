{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "N0WL7_ZUyAi2",
    "outputId": "8126e3a3-f330-4f23-bb9f-532be029f0d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "#Load Dataset\n",
    "(x_train , y_train) ,(x_test , y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape) #printing shape of training images , 60,000 images\n",
    "print(x_test.shape) #printing shape of test images , 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "5XlQY1ffyAi9",
    "outputId": "59b77e25-de96-406b-ad04-04e94c654590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in train data(60000, 28, 28)\n",
      "Samples in test data(10000, 28, 28)\n",
      "Dimensions of train data(28, 28)\n",
      "Dimensions of test data(28, 28)\n",
      "Labels in train data(60000,)\n",
      "Labels in test data(10000,)\n"
     ]
    }
   ],
   "source": [
    "#mnist dataset are 28*28 images with no other color channels\n",
    "print(\"Samples in train data\" + str(x_train.shape))\n",
    "print(\"Samples in test data\" + str(x_test.shape))\n",
    "\n",
    "print(\"Dimensions of train data\" + str(x_train[0].shape))\n",
    "print(\"Dimensions of test data\" + str(x_test[0].shape))\n",
    "\n",
    "print(\"Labels in train data\" + str(y_train.shape))\n",
    "print(\"Labels in test data\" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "ggmal90DyAjB",
    "outputId": "09538e0e-4461-4820-9233-452dd0ca005c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying images using opencv or matplotlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for i in range(0,6):\n",
    "    random_num = np.random.randint(0 , len(x_train)) #generates a number from 0 to 60000\n",
    "    img = x_train[random_num]\n",
    "    window_name = \"Random Sample\" + str(i)\n",
    "    cv2.imshow(\"ss\",img)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#plotting using matplotlib\n",
    "for i in range(331 , 335):\n",
    "    plt.subplot(i)\n",
    "    random_num = np.random.randint(0 , len(x_train))\n",
    "    plt.imshow(x_train[random_num] ,cmap = plt.get_cmap('gray'))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "huCMSoHkyAjF",
    "outputId": "2e88aff0-a964-413a-abfc-626bde56cf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#converting data into required shape\n",
    "#keras requires in shape = (Number of Samples , Rows , Columns , Depth)\n",
    "#in four dimensions , currently our data is (60000,28,28,1) in color (60000,28,28,3)\n",
    "#using numpys reshape we can add the extra dimension\n",
    "img_rows = x_train[0].shape[0] #takes the first image and the rows\n",
    "img_cols = x_train[0].shape[1] #takes the first image and returns columns\n",
    "print(img_rows)\n",
    "print(img_cols)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0] , img_rows , img_cols , 1)\n",
    "x_test = x_test.reshape(x_test.shape[0] , img_rows , img_cols , 1)\n",
    "#x_train.shape[0] returns the number of samples that is 60000\n",
    "\n",
    "\n",
    "#store and declare the input shape for the first layer of the cnn\n",
    "input_shape = (img_rows , img_cols , 1)\n",
    "\n",
    "#keras expects float32 datatype\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "#Normalize data to change the range from 0-255 to 0-1\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cdV6ob_yAjI"
   },
   "outputs": [],
   "source": [
    "#one hot encoding the labels because keras can only process numerical y data\n",
    "# one hot enconding represents each label in numerical form where the number of columns is the number of classes\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "num_samples = y_test.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "SDHgwfbJyAjK",
    "outputId": "7082e254-7ea7-4a54-c628-dae83b9ed9c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               1106040   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 1,126,066\n",
      "Trainable params: 1,126,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creating our model\n",
    "#start dropout small and end with 0.5\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Flatten\n",
    "from keras.layers import Conv2D , MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32 , kernel_size = (3,3) ,activation ='relu' , input_shape = input_shape))\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120 , activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes , activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = SGD(0.01) , metrics =['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "E4TNsOyAyAjO",
    "outputId": "e18773ee-b342-4c94-9e07-4d672564f121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.5636 - acc: 0.8230 - val_loss: 0.1916 - val_acc: 0.9431\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.2972 - acc: 0.9113 - val_loss: 0.1436 - val_acc: 0.9570\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.2335 - acc: 0.9305 - val_loss: 0.1161 - val_acc: 0.9645\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 219s 4ms/step - loss: 0.1888 - acc: 0.9439 - val_loss: 0.0870 - val_acc: 0.9736\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 220s 4ms/step - loss: 0.1520 - acc: 0.9550 - val_loss: 0.0701 - val_acc: 0.9780\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 221s 4ms/step - loss: 0.1284 - acc: 0.9621 - val_loss: 0.0576 - val_acc: 0.9814\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 223s 4ms/step - loss: 0.1156 - acc: 0.9651 - val_loss: 0.0532 - val_acc: 0.9831\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 223s 4ms/step - loss: 0.1021 - acc: 0.9693 - val_loss: 0.0500 - val_acc: 0.9844\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0931 - acc: 0.9726 - val_loss: 0.0456 - val_acc: 0.9853\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 223s 4ms/step - loss: 0.0856 - acc: 0.9742 - val_loss: 0.0437 - val_acc: 0.9857\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 224s 4ms/step - loss: 0.0809 - acc: 0.9757 - val_loss: 0.0408 - val_acc: 0.9865\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0759 - acc: 0.9773 - val_loss: 0.0387 - val_acc: 0.9875\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0713 - acc: 0.9781 - val_loss: 0.0379 - val_acc: 0.9866\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 229s 4ms/step - loss: 0.0684 - acc: 0.9784 - val_loss: 0.0360 - val_acc: 0.9868\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.0650 - acc: 0.9806 - val_loss: 0.0383 - val_acc: 0.9878\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 0.0618 - acc: 0.9811 - val_loss: 0.0337 - val_acc: 0.9882\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0599 - acc: 0.9814 - val_loss: 0.0360 - val_acc: 0.9884\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 213s 4ms/step - loss: 0.0597 - acc: 0.9813 - val_loss: 0.0364 - val_acc: 0.9870\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0546 - acc: 0.9829 - val_loss: 0.0346 - val_acc: 0.9880\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 267s 4ms/step - loss: 0.0514 - acc: 0.9841 - val_loss: 0.0347 - val_acc: 0.9882\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Test loss: 0.03471941893734038\n",
      "Test accuracy: 0.9882\n"
     ]
    }
   ],
   "source": [
    "#Training  our model\n",
    "#batch_size  how many samples in each batch depends on ram\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "final_model = model.fit(x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = (x_test , y_test) )#verbose how much information to see when training\n",
    "\n",
    "score = model.evaluate(x_test , y_test , verbose = 1)\n",
    "print(\"Test loss:\" , score[0])\n",
    "print(\"Test accuracy:\" , score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hfKy7qfoySH_",
    "outputId": "c2899203-05c6-4e64-b75e-02dc1442109d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:303: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from keras.models import model_from_json \n",
    "from keras.models import load_model\n",
    "\n",
    "#saving model weights\n",
    "model.save('C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning\\\\mnist_model_weights.h5')\n",
    "print(\"Model Saved\")\n",
    "\n",
    "#save model\n",
    "model_json = model.to_json()\n",
    "with open(r'C:\\Users\\Zahid\\Desktop\\Deep Learning\\mnist_model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "classifier = load_model('C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning\\\\mnist_model_weights.h5')\n",
    "\n",
    "with open(r'C:\\Users\\Zahid\\Desktop\\Deep Learning\\mnist_model.json','r') as jfile:\n",
    "            model = model_from_json(jfile.read())\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "PJKy5eaiz9oO",
    "outputId": "3a105d93-7fe9-48b5-d8c1-d47f5132575a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a439b34fc82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhistory_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mloss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "          #plotting loss and accuracy charts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = final_model.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1 , len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs , val_loss_values , label = \"Validation/Test Loss\")\n",
    "line2 = plt.plot(epochs , loss_values , label = \"Training Loss\")\n",
    "plt.setp(line1 , linewidth = 2.0 , marker = '+' , markersize = 10.0)\n",
    "plt.setp(line2 , linewidth = 2.0 , marker = '4' , markersize = 10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXXd8wEy2mRp"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1230: error: (-215:Assertion failed) dst.data == (uchar*)dst_ptr in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-890e85a95a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mdraw_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"imagefwe\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimageL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-890e85a95a70>\u001b[0m in \u001b[0;36mdraw_test\u001b[1;34m(name, pred, input_img)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mexpanded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_image\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_GRAY2BGR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_image\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m152\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m78\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_COMPLEX_SMALL\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mexpanded_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.0) C:\\projects\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:1230: error: (-215:Assertion failed) dst.data == (uchar*)dst_ptr in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "#Testing Data\n",
    "\n",
    "def draw_test(name , pred , input_img):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(input_img , 0,0,0 , imageL.shape[0] , cv2.BORDER_CONSTANT , value = BLACK)\n",
    "    expanded_image = cv2.cvtColor(expanded_image , cv2.COLOR_GRAY2BGR)\n",
    "    cv2.putText(expanded_image , str(pred) , (152 , 78) , cv2.FONT_HERSHEY_COMPLEX_SMALL , 4 , (0,255,0) , 2)\n",
    "    cv2.imshow(name , expanded_image)\n",
    "    \n",
    "for i in range(0,10):\n",
    "    rand = np.random.randint(0,len(x_test))\n",
    "    input_img = x_test[rand]\n",
    "\n",
    "    imageL = cv2.resize(input_img , None , fx=4 ,fy=4 , interpolation = cv2.INTER_CUBIC)\n",
    "    input_img = input_img.reshape(1,28,28,1)\n",
    "\n",
    "    res = str(classifier.predict_classes(input_img , 1 , verbose = 0)[0])\n",
    "\n",
    "    draw_test(\"imagefwe\" , res , imageL)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y22tsXRg4KVv"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mpimg' from 'matplotlib.image' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-75590419a4e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Visualizing the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel_diagram_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'mpimg' from 'matplotlib.image' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py)"
     ]
    }
   ],
   "source": [
    "#Visualizing the model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib.image import mpimg\n",
    "\n",
    "model_diagram_path = 'C:\\\\Users\\\\Zahid\\\\Desktop\\\\Deep Learning'\n",
    "\n",
    "#generate the model\n",
    "plot_model(model , to_file = model_diagram_path +'model_plot.png' , show_shapes = True , show_layer_names = True)\n",
    "\n",
    "img = mpimg.imread(model_diagrams_path + 'model_plot.png')\n",
    "plt.figure(figsize=(30,15))\n",
    "imgplot = plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST Detection using Keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
